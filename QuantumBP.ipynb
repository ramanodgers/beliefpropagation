{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec661e9d-0e7a-4fe9-829b-241d312d2762",
   "metadata": {},
   "source": [
    "# Quantum syndrome decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656678d1-e6d7-4159-87d1-a68a575ba883",
   "metadata": {},
   "source": [
    "Classical LDPC matrices are stored in \"files/[name].npy\" from working directory\n",
    "\n",
    "The notation used here will borrow from the following blog post [here](https://arthurpesah.me/blog/2022-05-21-classical-error-correction/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920ed584-cebd-4904-8d8c-02ba9811122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "import time\n",
    "from scipy.io import savemat\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd60921-4908-4959-a65e-226fa2bcf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1  = 'Dv2Dc3_G18_N114.npy'\n",
    "file2  = 'Dv2Dc6_G8_N36.npy'\n",
    "\n",
    "#classical\n",
    "CM1 = np.load('files/'+file1)\n",
    "CM2 = np.load('files/'+file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a78ae8c-7e56-4de6-85ec-05caac78376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface25 = np.array([[1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]],dtype=int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e7a528d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussianElimination(matrix, columns=None, diagonalize=True,\n",
    "                        successfulCols=None, q=2):\n",
    "        \"\"\"\n",
    "        gaussianElimination(matrix, columns=None, diagonalize=True, successfulCols=None, q=2)\n",
    "\n",
    "        The Gaussian elimination algorithm in :math:`\\mathbb F_q` arithmetics, turning a given\n",
    "        matrix into reduced row echelon form by elementary row operations.\n",
    "\n",
    "        .. warning:: This algorithm operates **in-place**!\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        matrix : np.int_t[:,::1]\n",
    "            The matrix to operate on.\n",
    "        columns : np.intp_t[:], optional\n",
    "            A sequence of column indices, giving the the order in which columns of the matrix are\n",
    "            visited. Defaults to ``range(matrix.shape[1])``.\n",
    "        diagonalize : bool, True\n",
    "            If ``True``, matrix elements above the pivots will be turned to zeros, leading to a\n",
    "            diagonal submatrix. Otherwise, the result contains an upper triangular submatrix.\n",
    "        successfulCols : np.intp_t[::1], optinonal\n",
    "            Numpy array in which successfully diagonalized column indices are stored. If supplied,\n",
    "            this array will be used for the return value. Otherwise, a new array will be created,\n",
    "            resulting in a slight performance drain.\n",
    "        q : int, optional\n",
    "            Field size in which operations should be performed. Defaults to ``2``.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.intp_t[::1]\n",
    "            Indices of successfully diagonalized columns.\n",
    "        \"\"\"\n",
    "        nrows = matrix.shape[0]\n",
    "        ncols = matrix.shape[1]\n",
    "        curRow = 0\n",
    "        colIndex = 0\n",
    "        numSuccessfulCols = 0\n",
    "        # assert q < cachedInvs.shape[0]\n",
    "\n",
    "        if successfulCols is None:\n",
    "            successfulCols = np.empty(nrows, dtype=np.intp)\n",
    "        if columns is None:\n",
    "            columns = np.arange(ncols, dtype=np.intp)\n",
    "        while True:\n",
    "            if colIndex >= columns.shape[0]:\n",
    "                break\n",
    "            curCol = columns[colIndex]\n",
    "            # search for a pivot row\n",
    "            pivotRow = -1\n",
    "            for row in range(curRow, nrows):\n",
    "                val = matrix[row, curCol]\n",
    "                if val != 0:\n",
    "                    pivotRow = row\n",
    "                    break\n",
    "            if pivotRow == -1:\n",
    "                # did not find a pivot row -> this column is linearly dependent of the previously\n",
    "                # visited; continue with next column\n",
    "                colIndex += 1\n",
    "                continue\n",
    "            if pivotRow > curRow:\n",
    "                # swap rows\n",
    "                for i in range(ncols):\n",
    "                    val = matrix[curRow, i]\n",
    "                    matrix[curRow, i] = matrix[pivotRow, i]\n",
    "                    matrix[pivotRow, i] = val\n",
    "            # do the actual pivoting\n",
    "            if matrix[curRow, curCol] > 1:\n",
    "                # \"divide\" by pivot element to set it to 1\n",
    "                if q > 2:\n",
    "                    factor = cachedInvs[q, matrix[curRow, curCol]]\n",
    "                    for i in range(ncols):\n",
    "                        matrix[curRow, i] = (matrix[curRow, i] * factor) % q\n",
    "            for row in range(curRow + 1, nrows):\n",
    "                val = matrix[row, curCol]\n",
    "                if val != 0:\n",
    "                    for i in range(ncols):\n",
    "                        if q == 2:\n",
    "                            matrix[row, i] ^= matrix[curRow, i]\n",
    "                        else:\n",
    "                            matrix[row, i] =  (matrix[row, i] -val*matrix[curRow, i]) % q\n",
    "            successfulCols[numSuccessfulCols] = curCol\n",
    "            numSuccessfulCols += 1\n",
    "            if numSuccessfulCols == nrows:\n",
    "                break\n",
    "            curRow += 1\n",
    "            colIndex += 1\n",
    "        if diagonalize:\n",
    "            for colIndex in range(numSuccessfulCols):\n",
    "                curCol = successfulCols[colIndex]\n",
    "                for row in range(colIndex):\n",
    "                    val = matrix[row, curCol]\n",
    "                    if val != 0:\n",
    "                        for i in range(ncols):\n",
    "                            if q == 2:\n",
    "                                matrix[row, i] ^= matrix[colIndex, i]\n",
    "                            else:\n",
    "                                matrix[row, i] = (matrix[row, i] - val*matrix[colIndex, i]) % q\n",
    "        return successfulCols[:numSuccessfulCols]\n",
    "\n",
    "def rank(matrix, q=2):\n",
    "    \"\"\"Return the rank (in GF(q)) of a matrix.\"\"\"\n",
    "    diagCols = gaussianElimination(matrix.copy(), diagonalize=False, q=q)\n",
    "    return diagCols.size\n",
    "\n",
    "def orthogonalComplement(matrix, columns=None, q=2):\n",
    "    \"\"\"Computes an orthogonal complement (in GF(q)) to the given matrix.\"\"\"\n",
    "    matrix = np.asarray(matrix.copy())\n",
    "    m, n = matrix.shape\n",
    "    unitCols = gaussianElimination(matrix, columns, diagonalize=True, q=q)\n",
    "    nonunitCols = np.array([x for x in range(n) if x not in unitCols])\n",
    "    rank = unitCols.size\n",
    "    nonunitPart = matrix[:rank, nonunitCols].transpose()\n",
    "    k = n - rank\n",
    "    result = np.zeros((k, n), dtype=np.int32)\n",
    "    for i, c in enumerate(unitCols):\n",
    "        result[:, c] = (-nonunitPart[:, i]) % q\n",
    "    for i, c in enumerate(nonunitCols):\n",
    "        result[i, c] = 1\n",
    "    return result\n",
    "\n",
    "#given a string of stabilizers and number of encoding qubits, convert into 2d array parity check matrix\n",
    "def convert(strings, leng, plural=True, alpha=True):\n",
    "    if plural:\n",
    "        total = len(strings)\n",
    "    else:\n",
    "        total = 1\n",
    "    stabilizers = np.zeros([total,leng],dtype=int)\n",
    "    filler=[]\n",
    "    if alpha:\n",
    "        match_x = 'X'\n",
    "        match_z = 'Z'\n",
    "        #match_y = 'Y'\n",
    "    else:\n",
    "        match_x = '1'\n",
    "        match_z = '1'\n",
    "    length = leng\n",
    "    stabilizers =np.zeros([total,leng],dtype=int)\n",
    "    for i in range(total):\n",
    "        curr_stab = np.zeros((length,),dtype=int)\n",
    "        for j in range(leng):\n",
    "            if plural:\n",
    "                if strings[i][j]==match_x:\n",
    "                    curr_stab[j]=1\n",
    "                elif strings[i][j]==match_z:\n",
    "                    curr_stab[j]=1\n",
    "                else:\n",
    "                    curr_stab[j]=0\n",
    "            else:\n",
    "                if strings[j]==match_x:\n",
    "                    curr_stab[j]=1\n",
    "                elif strings[j]==match_z:\n",
    "                    curr_stab[j]=1\n",
    "                else:\n",
    "                    curr_stab[j]=0\n",
    "        stabilizers[i]=curr_stab\n",
    "    return stabilizers  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c320f53-28a5-44d4-b7c7-afd0b6836e85",
   "metadata": {},
   "source": [
    "## Tools for Encoding and Error Simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246112f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(H):\n",
    "     return np.transpose(orthogonalComplement(H))\n",
    "\n",
    "def AIk(M):\n",
    "    #returns the given matrix in the A:Ik form \n",
    "    return np.concatenate((M,np.identity(M.shape[0], dtype = np.int64)), axis = 1)\n",
    "\n",
    "def word_gen(G, x = None):\n",
    "    #generates some codeword for a given generator matrix \n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    #x is the encoded info (k x 1)\n",
    "    if x is None:\n",
    "        x = rng.integers(2, size=G.shape[1])\n",
    "    # y is the codeword\n",
    "    y = np.remainder(np.dot(G,x),2)\n",
    "    return y \n",
    "\n",
    "def random_data(length):\n",
    "    rng = np.random.default_rng()\n",
    "    return rng.integers(2, size = length)\n",
    "    \n",
    "def getx(H,y):\n",
    "    return y[:H.shape[1]-H.shape[0]]\n",
    "\n",
    "def newgetx(G,y):\n",
    "    return solver(G,y)\n",
    "    \n",
    "def solver(m, b):\n",
    "    b = b.reshape(-1,1)\n",
    "    print(m.shape)\n",
    "    print(b.shape)\n",
    "    # aug = np.append(m, b, axis =1)\n",
    "    aug = np.hstack([m, b])\n",
    "    successful = gaussianElimination(aug)\n",
    "    xguess = np.zeros(m.shape[1])\n",
    "    i = 0\n",
    "    while i < len(xguess):\n",
    "        xguess[successful[i]] = aug[i][aug.shape[1]-1]\n",
    "        i +=1\n",
    "    return xguess\n",
    "\n",
    "def iid_error(codeword, p):\n",
    "    # randomly disturbs a given codeword with iid probability p of an error on any bit\n",
    "    # generate a random codeword length string and add it to the codeword mod 2\n",
    "    rng = np.random.default_rng()\n",
    "    error = rng.choice(2, size = codeword.shape[0], p = [1-p,p])\n",
    "    corrupted = np.remainder(codeword + error, 2) \n",
    "    return corrupted\n",
    "\n",
    "def dist_error(codeword, distance):\n",
    "    #corrupts the data with a given number of bitflips.\n",
    "    error = np.array([0] * (codeword.shape[0]-distance) + [1] * (distance))\n",
    "    np.random.shuffle(error)\n",
    "    corrupted = np.remainder(codeword + error, 2, dtype= int) \n",
    "    return corrupted\n",
    "\n",
    "def code_rate(M):\n",
    "    # NB code rate assumes a linear code for quantum encoding, usually not linear code\n",
    "    m = M.shape[0]\n",
    "    n = M.shape[1]\n",
    "    k = n-m\n",
    "    return \"Code Rate:\" + str(k/n)\n",
    "\n",
    "def HGP(h1,h2):\n",
    "    m1,n1=np.shape(h1)\n",
    "    m2,n2=np.shape(h2)\n",
    "    m1=np.identity(m1,dtype=int)\n",
    "    n1=np.identity(n1,dtype=int)\n",
    "    m2=np.identity(m2,dtype=int)\n",
    "    n2=np.identity(n2,dtype=int)\n",
    "    \n",
    "    hx1=np.kron(h1,n2)\n",
    "    hx2=np.kron(m1,h2.T)\n",
    "    hx = np.hstack([hx1,hx2])\n",
    "    hz1=np.kron(n1,h2)\n",
    "    hz2=np.kron(h1.T,m2)\n",
    "    hz = np.hstack([hz1,hz2 ])\n",
    "    \n",
    "    hxtemp=np.vstack([np.zeros(hz.shape,dtype=int),hx])\n",
    "    hztemp=np.vstack([hz,np.zeros(hx.shape,dtype=int)])\n",
    "    return np.hstack([hztemp,hxtemp])\n",
    "\n",
    "def parity_checker(H,y):\n",
    "    #returns the s = He syndrome\n",
    "    He = np.remainder(np.dot(H,y),2)\n",
    "    return He\n",
    "\n",
    "def Tanner_gen(M):\n",
    "    #directed adjacency graph in dict form \n",
    "    # M is m x k where m is the number of parity checks\n",
    "    m = M.shape[0]\n",
    "    k = M.shape[1]\n",
    "    #to keep integer values, the variable nodes are stored as their coord + k \n",
    "    adj = dict()\n",
    "    for i in range(M.shape[0]):\n",
    "        adj[i] = dict()\n",
    "        for j in range(M.shape[1]):\n",
    "            v = j+k\n",
    "            if  i == 0:\n",
    "                adj[v] = dict()\n",
    "            if M[i][j] == 1:\n",
    "                adj[i][v] = 1\n",
    "                adj[v][i] = 1\n",
    "    return adj \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b2ebd5a-d89d-4bba-ad15-f6934c0fc5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1]\n",
      " [0 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "rep3 = np.array([[1,1,0],[0,1,1]])\n",
    "HGPrep3  = HGP(rep3,rep3)\n",
    "\n",
    "#constructing project stabilizers and pcm\n",
    "project_stabilizers = ['ZZZZIIIIIIIIIIIII','ZIZIZZIIIIIIIIIII',\n",
    "                       'IIIIZZIIZZIIIIIII','IIIIIIZZIIZZIIIII',\n",
    "                      'IIIIIIIIZZIIZZIII','IIIIIIIIIIZZIIZZI',\n",
    "                       'IIIIIIIZIIIZIIIZZ','IIZZIZZIIZZIIZZII']\n",
    "pcm17 = convert(project_stabilizers, 17)\n",
    "print(pcm17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c9c401-3023-49ed-a9da-1a966ce33666",
   "metadata": {},
   "source": [
    "## OSD Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6db6f8-f081-4f8f-8855-20ede5a40b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input is log ratio guesses as in the decoder self.Q form\n",
    "# output colz are the first columns in bp_sort that can be reduced using gaussianElimination\n",
    "# output 1 is the binary string for which of those columns have errors by OSD\n",
    "def osd_0(H, syndrome, bp_probs):\n",
    "    bp_sort = np.argsort(bp_probs)\n",
    "    colz  = gaussianElimination(H.copy(), columns=bp_sort, diagonalize=False)\n",
    "    H_OSD = H[:,colz]\n",
    "    # compute inverse\n",
    "    H_AUG = np.ascontiguousarray(np.hstack([H_OSD, syndrome[:,np.newaxis]]), dtype = int)\n",
    "    gaussianElimination(H_AUG)\n",
    "    #OSD does the same thing as solver()\n",
    "    return colz, H_AUG[:H_OSD.shape[1], -1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915bdf0-a8a5-481c-a7c7-f07332fe69dc",
   "metadata": {},
   "source": [
    "## Belief Propagation decoding\n",
    "much based on this article\n",
    "\n",
    "https://yair-mz.medium.com/decoding-ldpc-codes-with-belief-propagation-43c859f4276d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb4e935-dc0b-4e71-9fbf-f46227e51c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the input is the m length syndrome and the output is n length estimated error\n",
    "# the goal in a syndrome decoder is to generate the input error from a syndrome\n",
    "class syndrome_BP:\n",
    "    def __init__(self, H, syndrome, max_iter, p, OSD = False, higher = False):\n",
    "        # this class assumes the iid errors as above\n",
    "        # syndrome based belief propagation\n",
    "        self.syndrome = np.array(syndrome)\n",
    "        self.H = H\n",
    "        self.Q = np.zeros(self.H.shape[1])\n",
    "        self.m = self.H.shape[0]\n",
    "        self.n = self.H.shape[1]\n",
    "        self.k = self.n - self.m\n",
    "        self.max_iter = max_iter\n",
    "        self.guess = np.zeros(self.H.shape[1], dtype = int)\n",
    "        self.p = p\n",
    "        self.OSD  = OSD\n",
    "        self.higherOSD  = higher\n",
    "\n",
    "        #the log probability that the noise values for each bit is zero \n",
    "        self.Lconst = np.full((self.H.shape[1]),np.log(1-self.p) - np.log(self.p))\n",
    "        \n",
    "        #belief prop\n",
    "        self.Lqij = np.zeros((self.H.shape[0],self.H.shape[1]))\n",
    "        self.Lrij = np.zeros((self.m,self.n))\n",
    "        self.coords = []\n",
    "        \n",
    "    def phi(self,x):\n",
    "        if x ==0:\n",
    "            return 0\n",
    "        return -np.log(np.tanh(np.abs(x)/2))\n",
    "    \n",
    "    def r_update(self):\n",
    "            \n",
    "        for coord in self.coords:\n",
    "            if self.syndrome[coord[0]] == 1:\n",
    "                sign = -1\n",
    "            else:\n",
    "                sign = 1\n",
    "            tempsum = 0\n",
    "            for subcoord in self.coords:\n",
    "                if subcoord[0] == coord[0]:\n",
    "                    if subcoord[1] != coord[1]:\n",
    "                        if self.Lqij[subcoord[0]][subcoord[1]] == 0:\n",
    "                            continue\n",
    "                        else:\n",
    "                            temp = self.Lqij[subcoord[0]][subcoord[1]]\n",
    "                            tempsum += self.phi(temp)\n",
    "                        \n",
    "            self.Lrij[coord[0]][coord[1]] = sign * self.phi(tempsum)\n",
    "\n",
    "\n",
    "    def q_update(self):\n",
    "        for coord in self.coords: \n",
    "            tempsum = 0\n",
    "            for subcoord in self.coords:\n",
    "                if subcoord[1] == coord[1]:\n",
    "                    if subcoord[0] != coord[0]:\n",
    "                        tempsum += self.Lrij[subcoord[0]][subcoord[1]]\n",
    "            \n",
    "            self.Lqij[coord[0]][coord[1]] = self.Lconst[coord[1]] + tempsum\n",
    "\n",
    "    def guesser(self):\n",
    "        addend = np.sum(self.Lrij, axis=0)\n",
    "        Q  = self.Lconst + addend\n",
    "        self.change = np.sum(np.abs(Q - self.Q))/len(Q)\n",
    "        self.Q = Q\n",
    "        for var in range(self.n):\n",
    "\n",
    "            if self.Q[var] < 0:\n",
    "                self.guess[var] = 1\n",
    "            else:\n",
    "                self.guess[var] = 0\n",
    "\n",
    "\n",
    "        if np.any(self.guess):\n",
    "            He = np.remainder(np.dot(self.H,self.guess),2)\n",
    "            #stop condition\n",
    "            if np.array_equal(He,self.syndrome):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    \n",
    "    def initialize(self):\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                if self.H[i][j] == 1:\n",
    "                    self.coords.append((i,j))\n",
    "        for coord in self.coords: \n",
    "            self.Lqij[coord[0]][coord[1]] = 1\n",
    "            self.Lrij[coord[0]][coord[1]] = 1\n",
    "        \n",
    "\n",
    "    def decoder(self):\n",
    "        if len(self.syndrome) != self.m:\n",
    "            raise ValueError(\"incorrect block size\")\n",
    "        self.initialize()\n",
    "        \n",
    "        #immediately returns if the syndrome is zero \n",
    "        if not np.any(self.syndrome):\n",
    "            return self.guess, None\n",
    "        \n",
    "        for _ in range(self.max_iter):\n",
    "            self.r_update()\n",
    "\n",
    "            self.q_update()\n",
    "            \n",
    "            result = self.guesser()\n",
    "            if result:\n",
    "                #success\n",
    "                return self.guess, False\n",
    "        \n",
    "        if self.OSD or self.higherOSD:\n",
    "            self.guess = np.zeros(self.H.shape[1], dtype = int)\n",
    "            cols, OSDerror = osd_0(self.H, self.syndrome, self.Q)\n",
    "            for i in range(len(cols)):\n",
    "                self.guess[cols[i]] = OSDerror[i]\n",
    "            He = np.remainder(np.dot(self.H,self.guess),2)\n",
    "            # stop condition\n",
    "            if not np.array_equal(He,self.syndrome):\n",
    "                print(\"\\n what \\n\")\n",
    "                \n",
    "        #now for higher-order OSD\n",
    "        if self.higherOSD:\n",
    "            \n",
    "            self.guess = np.zeros(self.H.shape[1], dtype = int)\n",
    "            Hs= self.H[:,cols]\n",
    "            print(self.H.shape)\n",
    "            print(Hs.shape)\n",
    "            print(OSDerror.shape)\n",
    "            print(Hs)\n",
    "            print(OSDerror)\n",
    "            first_term = solver(Hs,OSDerror)\n",
    "            \n",
    "            lamb = 30\n",
    "            \n",
    "            first_guess =self.guess\n",
    "            tcolz = [*range(self.H.shape[1])]\n",
    "            tcolz = np.setdiff1d(tcolz,cols)\n",
    "            bp_sort = np.argsort(self.Q)\n",
    "            t_sort = bp_sort[np.in1d(bp_sort, tcolz)]\n",
    "            Ht= self.H[:,tcolz]\n",
    "\n",
    "\n",
    "            \n",
    "            #weight-one configs\n",
    "            for i, bit in enumerate(t_sort):\n",
    "                #here self.guess is et\n",
    "                # need to define an et length vector here \n",
    "                et = np.zeros(len(t_sort), dtype = int)\n",
    "                et[bit] = 1\n",
    "                \n",
    "                second_term  = solver(Hs,np.remainder(np.dot(self.Ht,et),2))\n",
    "                first_half = first_term + second_term\n",
    "                for i in range(len(cols)):\n",
    "                    self.guess[cols[i]] = first_half[i]\n",
    "                self.guess[bit] = 1\n",
    "                He = np.remainder(np.dot(self.H,self.guess),2)\n",
    "                if np.array_equal(He,self.syndrome):\n",
    "                    break\n",
    "                self.guess = np.zeros(self.H.shape[1], dtype = int)\n",
    "                \n",
    "                \n",
    "            #weight two configs\n",
    "            for combo in combinations(tcolz[:lamb],2):\n",
    "                self.guess = np.zeros(self.H.shape[1], dtype = int)\n",
    "                et = np.zeros(len(t_sort), dtype = int)\n",
    "                et[combo[0]] = 1\n",
    "                et[combo[1]] = 1\n",
    "                second_term  = solver(Hs,np.remainder(np.dot(self.Ht,et),2))\n",
    "                first_half = first_term + second_term\n",
    "                for i in range(len(cols)):\n",
    "                    self.guess[cols[i]] = first_half[i]\n",
    "                self.guess[combo[0]] = 1\n",
    "                self.guess[combo[1]] = 1\n",
    "                He = np.remainder(np.dot(self.H,self.guess),2)\n",
    "                if np.array_equal(He,self.syndrome):\n",
    "                    break\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        return self.guess, True  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c5897-a92c-46bb-965a-bcc71e82c8c9",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e2ac89-34f9-4625-ac24-61a538eb9afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codeword BP now doesnt decode the estimated y codeword string. This introduced a procedural mismatch betweeen codeword and syndrome decoding. \n",
    "\n",
    "def tester (A, err_model, err_param,num=100, max_iter =30, only_error = False, verbose = 0, OSD = False, higher = False):\n",
    "    #tests the entire workflow of the decoder over num tests\n",
    "\n",
    "    H = A\n",
    "    success = 0\n",
    "    \n",
    "    #this implicitly tests if the error generation is dist or iid\n",
    "    # if dist, it uses some default error for belief propagation. \n",
    "    if err_param >= 1:\n",
    "        p =0.02\n",
    "    else:\n",
    "        p = err_param\n",
    "    counter = 0\n",
    "    \n",
    "    for _ in range(num):\n",
    "        #directly generates an error vector to then encode into a syndrome\n",
    "        y = np.zeros(H.shape[1],dtype = int)\n",
    "        error = err_model(y, err_param)\n",
    "\n",
    "        # if we want to exclude any uncorrupted codewords\n",
    "        if only_error:\n",
    "            while np.array_equal(y,error):\n",
    "                error = err_model(y, err_param)\n",
    "\n",
    "        syndrome = np.remainder(np.dot(H, error),2)\n",
    "        BP = syndrome_BP(H,syndrome,max_iter,p,OSD = OSD, higher = higher )\n",
    "        est_error, maxed = BP.decoder()\n",
    "        delta = np.sum(np.abs(error-est_error))\n",
    "        if verbose==3:\n",
    "            if delta != 0:\n",
    "                if not maxed:\n",
    "                    print(\"matching syndrome\")\n",
    "                else: \n",
    "                    print(\"maxed\")\n",
    "                print(syndrome)\n",
    "                print(error)\n",
    "                print(est_error)\n",
    "                print(delta, end = \"\\n\\n\")\n",
    "                \n",
    "        #in the syndrome context its the number of errors in the error\n",
    "        if delta == 0:\n",
    "            success+=1\n",
    "        else:\n",
    "            counter+=delta\n",
    "\n",
    "    return success/num, counter\n",
    "\n",
    "def batch_tester(param_list, M, err_model = 'd', verbose = 0, OSD  = False,  higher = False,  num = 2000):\n",
    "    #wrappper function to tester which returns statistics and prints with varying verbosity \n",
    "    \n",
    "    distance = np.min(np.sum(M, axis = 0)) + 1\n",
    "    success = []\n",
    "    preerror = []\n",
    "    posterror = []\n",
    "    \n",
    "    n = M.shape[1]\n",
    "    \n",
    "    start = time.time()\n",
    "    if err_model == 'd':\n",
    "        for param in param_list:\n",
    "            success_rate, count = tester(M, dist_error, param, num = num, max_iter = 10, verbose = verbose, OSD = OSD, higher = higher)\n",
    "            if verbose >= 2:\n",
    "                print(\"Error distance: \" + str(param) + \"  Error proportion: \" + \"{:.4f}\".format(param/(n)))\n",
    "                print(\"bit error rate after decoding: \" + \"{:.4f}\".format(count/(num*(n))))\n",
    "                print(\"Successful decoding rate: \" + str(success_rate) + '\\n')\n",
    "            success.append(success_rate)\n",
    "            preerror.append(param/(n))\n",
    "            posterror.append(count/(num*(n)))\n",
    "            end = time.time()\n",
    "            if verbose >=1:\n",
    "                print(\"time for \" +str(param) + \": \" +\"{:.4f}\".format(end - start))\n",
    "            start = end \n",
    "            \n",
    "    elif err_model == 'p':\n",
    "        for param in param_list:\n",
    "            success_rate, count = tester(M, iid_error, param, num = num, max_iter = 10, verbose = verbose, OSD = OSD, higher = higher)\n",
    "            if verbose >= 2:\n",
    "                print(\"bit corruption probability: \" + str(param))\n",
    "                print(\"bit error rate after decoding: \" + \"{:.4f}\".format(count/(num*(n))))\n",
    "                print(\"Successful decoding rate: \" + str(success_rate) + '\\n')\n",
    "            success.append(success_rate)\n",
    "            preerror.append(param)\n",
    "            posterror.append(count/(num*(n)))\n",
    "            end = time.time()\n",
    "            if verbose >=1:\n",
    "                print(\"time for \" +str(param) + \": \" +\"{:.4f}\".format(end - start))\n",
    "            start = end \n",
    "        \n",
    "    return [param_list, success, preerror, posterror]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4a482d9-819d-427b-b144-ddccc1654e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing syndrome and codeword decoding performance\n",
    "\n",
    "def distance_plot_test(M, verbose = 0):\n",
    "    #plots performance of a code matrix as a function of error distance\n",
    "    \n",
    "    #preprint\n",
    "    distance = np.min(np.sum(M, axis = 0)) + 1\n",
    "    print('For LDPC with ' + str(M.shape[0]) + \" parity check variables, \" + str(M.shape[1]) +  ' encoded logical bits:')\n",
    "    # print(\"distance: \" +str(distance))\n",
    "    # print(\"correctable distance: \" +str((distance-1)//2))\n",
    "    # print(code_rate(M), end = '\\n\\n')\n",
    "    \n",
    "    #testing\n",
    "    print(\"BP DECODING\")\n",
    "    BP_results = batch_tester([1,2,3,4,5,6,], M, err_model = 'd', verbose = verbose, OSD  = False)\n",
    "    print(\"BP+OSD DECODING\")\n",
    "    BPOSD_results = batch_tester([1,2,3,4,5,6,], M, err_model = 'd', verbose = verbose, OSD  = True)\n",
    "    differential = np.array(BPOSD_results[1]) - np.array(BP_results[1])\n",
    "    \n",
    "    #plotting\n",
    "    plt.plot(BP_results[0], BP_results[1], 'bo-',label = \"BP decoding\")\n",
    "    plt.plot(BPOSD_results[0], BPOSD_results[1], 'yo-',label = \"BP+OSD decoding\")\n",
    "    # plt.plot(BPOSD_results[0], differential, 'go-',label = \"BPOSD - BP\")\n",
    "    plt.legend()\n",
    "    plt.title('complete decoding success rate')\n",
    "    plt.savefig(\"pcm17BPBPOSDdistancetest.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def rate_plot_test(M, verbose = 0):\n",
    "    #plots performance of a code matrix as a function os idd bit error rate\n",
    "\n",
    "    #preprint\n",
    "    distance = np.min(np.sum(M, axis = 0)) + 1\n",
    "    print('For LDPC with ' + str(M.shape[0]) + \" parity check variables, \" + str(M.shape[1]) +  ' encoded logical bits:')\n",
    "    # print(\"distance: \" +str(distance))\n",
    "    # print(\"correctable distance: \" +str((distance-1)//2))\n",
    "    # print(code_rate(M), end = '\\n\\n')\n",
    "    \n",
    "    print(\"BP DECODING\")\n",
    "    BP_results = batch_tester([0.005,0.01,0.02,0.04,0.06,0.08,0.1], M, err_model = 'p', verbose = verbose, OSD = False)\n",
    "    print(\"BP+OSD DECODING\")\n",
    "    BPOSD_results = batch_tester([0.005,0.01,0.02,0.04,0.06,0.08,0.1], M, err_model = 'p', verbose = verbose, OSD  =True)\n",
    "    differential = np.array(BP_results[3]) - np.array(BPOSD_results[3])\n",
    "    \n",
    "    #plotting\n",
    "    plt.plot(BP_results[2], BP_results[3], 'bo-',label = \"BP decoding\")\n",
    "    plt.plot(BPOSD_results[2], BPOSD_results[3], 'yo-',label = \"BP+OSD decoding\")\n",
    "    # plt.plot(BPOSD_results[2], differential, 'go-',label = \"BP - BPOSD\")\n",
    "    \n",
    "    plt.yscale('log')\n",
    "    plt.title('pre vs post bit error rate')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"pcm17BPBPOSDratetest.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "488ddb41-5b77-46a9-83ad-77a378f9f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for 1: 0.0368\n",
      "time for 2: 0.1241\n",
      "time for 3: 0.0245\n",
      "time for 4: 0.1219\n"
     ]
    }
   ],
   "source": [
    "ee  = batch_tester([1,2,3,4], CM2, err_model = 'd', verbose = 1, OSD  = True, num=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cac98-bc82-49cc-99f8-6fc867ec715b",
   "metadata": {},
   "source": [
    "So OSD on CM1 never leads to an error in the OSD, OSD on CM2 works half the time, and OSD on surface 25 works most of the time. This is likely due to an error in the inversion and hence an error in gaussianelim. Through investigation we could instead solve the equation using the LU decomposition of the matrix, rather than attempting inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c00638f9-57c2-4169-a1d2-151af95c9adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For LDPC with 8 parity check variables, 17 encoded logical bits:\n",
      "BP DECODING\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m M \u001b[38;5;129;01min\u001b[39;00m [pcm17]:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdistance_plot_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     rate_plot_test(M, verbose \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m, in \u001b[0;36mdistance_plot_test\u001b[0;34m(M, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(\"distance: \" +str(distance))\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(\"correctable distance: \" +str((distance-1)//2))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(code_rate(M), end = '\\n\\n')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#testing\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBP DECODING\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m BP_results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_tester\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOSD\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBP+OSD DECODING\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m BPOSD_results \u001b[38;5;241m=\u001b[39m batch_tester([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,], M, err_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m verbose, OSD  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[18], line 63\u001b[0m, in \u001b[0;36mbatch_tester\u001b[0;34m(param_list, M, err_model, verbose, OSD, higher, num)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m param_list:\n\u001b[0;32m---> 63\u001b[0m         success_rate, count \u001b[38;5;241m=\u001b[39m \u001b[43mtester\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOSD\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mOSD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigher\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhigher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError distance: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(param) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Error proportion: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(param\u001b[38;5;241m/\u001b[39m(n)))\n",
      "Cell \u001b[0;32mIn[18], line 29\u001b[0m, in \u001b[0;36mtester\u001b[0;34m(A, err_model, err_param, num, max_iter, only_error, verbose, OSD, higher)\u001b[0m\n\u001b[1;32m     27\u001b[0m syndrome \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mremainder(np\u001b[38;5;241m.\u001b[39mdot(H, error),\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     28\u001b[0m BP \u001b[38;5;241m=\u001b[39m syndrome_BP(H,syndrome,max_iter,p,OSD \u001b[38;5;241m=\u001b[39m OSD, higher \u001b[38;5;241m=\u001b[39m higher )\n\u001b[0;32m---> 29\u001b[0m est_error, maxed \u001b[38;5;241m=\u001b[39m \u001b[43mBP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m delta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mabs(error\u001b[38;5;241m-\u001b[39mest_error))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m:\n",
      "Cell \u001b[0;32mIn[8], line 103\u001b[0m, in \u001b[0;36msyndrome_BP.decoder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguess, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_update()\n\u001b[1;32m    107\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguesser()\n",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m, in \u001b[0;36msyndrome_BP.r_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subcoord[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m coord[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subcoord[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m coord[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLqij[subcoord[\u001b[38;5;241m0\u001b[39m]][\u001b[43msubcoord\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for M in [pcm17]:\n",
    "    distance_plot_test(M, verbose = 0)\n",
    "    rate_plot_test(M, verbose =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e6b63-d130-49c1-a6f5-17fd2192eb76",
   "metadata": {},
   "source": [
    "Very confusing results. OSD improves the total success rate on every code. OSD seems to be akin to codeword decoding on CM1. On the surface25 code it increases the total success rate at the expense of increasing the bit posterror rate (it gets it right more, but when it's wrong, it's more wrong).\n",
    "\n",
    "- I have fixed the issue with inversion and OSD now seems to always work \n",
    "\n",
    "NB: THE PAPER USES LOGICAL ERROR RATE NOT NOISE POST ERROR BIT RATE - is is the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74829ac-8d48-4cda-b55b-5026b9b57f6a",
   "metadata": {},
   "source": [
    "## Gradio integration (codeword decoding)\n",
    "My idea is that the user inputs some int. I convert that to binary and reshape it to be a codeword for the bigger LDPC matrix, disturb with a given distance, and then recover it through BP decoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e14b85-427a-4c71-add5-c75a01e35276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimalToBinary(n):\n",
    "    return bin(n).replace(\"0b\", \"\")\n",
    "\n",
    "def format_input(binstr, length):\n",
    "    short = np.array([*binstr], dtype=np.int8)\n",
    "    if len(short) <= length: \n",
    "        return np.pad(short, (length - len(short), 0), 'constant')\n",
    "    else:\n",
    "        raise ValueError(\"input too large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90241094-32bd-4dc5-9f37-a1dc23994c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"This is a toy belief propagation decoder. Pick an input number, error distance and LDPC encoding. \\\n",
    "Your number will convert to binary, then encode, then be corrupted by your error distance. See the decoded result given your choice of LDPC matrix.\\\n",
    "\\n\\n (It refreshes with every change to the input and might miss a change if the previous one is loading)\"\n",
    "\n",
    "def arr2string(arr):\n",
    "    return ''.join(str(int(x)) for x in arr)\n",
    "\n",
    "def greet(number, dist, size):\n",
    "    #outputs binary, encoded binary, corrupted binary, recovered binary, decoded binary, int output, \n",
    "    if size == 'small':\n",
    "        M = CM2\n",
    "    else:\n",
    "        M = CM1\n",
    "    H1 = AIk(M)\n",
    "    G1 = generator(M)\n",
    "    \n",
    "    try:\n",
    "        number = int(number)\n",
    "    except: \n",
    "        raise ValueError(\"not a number\")\n",
    "        \n",
    "    #string\n",
    "    binary = arr2string(format_input(decimalToBinary(number), H1.shape[1]-H1.shape[0]))\n",
    "    \n",
    "    #np array\n",
    "    encbin = word_gen(G1, x=format_input(binary, M.shape[1]))\n",
    "    \n",
    "    #np array \n",
    "    corrupted = dist_error(encbin, dist)\n",
    "    BP = Belief_prop(H1,corrupted,10,0.02)\n",
    "   \n",
    "    #np array \n",
    "    recovered, _ = BP.decoder()\n",
    "    \n",
    "    #np array \n",
    "    decoded = getx(H1,recovered)\n",
    "    \n",
    "    # int \n",
    "\n",
    "    out = int(arr2string(decoded),2 )\n",
    "\n",
    "    return (\n",
    "        binary, \n",
    "        arr2string(encbin),\n",
    "        arr2string(corrupted),\n",
    "        arr2string(recovered),\n",
    "        arr2string(decoded),\n",
    "        out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc9316-df5a-44b0-9475-d9518d0c2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \n",
    "            gr.Slider(0, 5, step = 1, label = \"Error Distance\"), \n",
    "            gr.Radio([\"small\", \"big\"], label=\"LDPC matrix\", info=\"How robust and large should the LDPC matrix be?\", value = 'big')],\n",
    "    outputs=[gr.Textbox(label=\"Input Binary\"), gr.Textbox(label=\"Encoded Binary\"),\n",
    "             gr.Textbox(label=\"Corrupted Binary\"),gr.Textbox(label=\"Binary Recovered after Belief Propagation Decoding\"),\n",
    "             gr.Textbox(label=\"Decoded Binary\"), gr.Number(label = \"Int Output\")],\n",
    "    theme=gr.themes.Monochrome(),\n",
    "    title=\"Classical Belief Propagation decoding\",\n",
    "    description = description, \n",
    "    allow_flagging = 'never',\n",
    "    live = True\n",
    "\n",
    ")\n",
    "demo.launch( share = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec566125-6620-476c-8061-29edbbb7c9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
